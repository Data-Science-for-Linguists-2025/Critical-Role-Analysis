{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5877ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  #just in case\n",
    "import nltk\n",
    "from nltk.tokenize import SyllableTokenizer  #for tokenizing syllables\n",
    "from nltk.tokenize import RegexpTokenizer   #for word tokenizing to ignore punctuation\n",
    "import itertools #used later to flatten/merge a list\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9638dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phonemizer\n",
    "from phonemizer.backend.espeak.wrapper import EspeakWrapper\n",
    "\n",
    "# Must point to eSpeak NG's library dll\n",
    "EspeakWrapper.set_library(r'C:\\Program Files\\eSpeak NG\\libespeak-ng.dll')\n",
    "\n",
    "from phonemizer.backend import EspeakBackend\n",
    "from phonemizer.punctuation import Punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5239da",
   "metadata": {},
   "source": [
    "### How Jargon-y is DND?\n",
    "\n",
    "To take a look, I grabbed my copy of the Player's Handbook (PHB) and converted it to a text file. I won't be sharing since the copyright belongs to Wizards of the Coast, but I will be discussing my findings here. \n",
    "\n",
    "1. [Flesch–Kincaid readability test](#Flesch–Kincaid-readability-test)\n",
    "    - [Flesch–Kincaid Calculations](#Running-the-Calculations)\n",
    "    - [Results](#Results)\n",
    "<br>\n",
    "<br>\n",
    "2. [SMOG Readability Test](#SMOG-Readability-Test)\n",
    "    - [Results](#SMOG-Results)\n",
    "<br>\n",
    "<br>\n",
    "3. [Readability Thoughts](#Thoughts-about-Readability-Scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00196815",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/PHB.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7499b832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1220025"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b13daeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = Punctuation(';:,.!\\'\"?()-').remove(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f348dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "phbtext = tokenizer.tokenize(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a358d4ff",
   "metadata": {},
   "source": [
    "Our total tokenized word count for the Player's Handbook is below. This excludes punctuation unlike in the usual nltk tokenizing, since the measurements I'm going to be using don't need that information. There's a short glance at a small section to get a feel for what we're looking at. The transformation into a .txt file was not perfect because of some text formatting in the original form, but I did the best I could without spending an excessive amount of time correcting every single issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "819b62c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215058"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phbtext) #total words (roughly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "774ac905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you',\n",
       " 'a',\n",
       " 'different',\n",
       " 'way',\n",
       " 'to',\n",
       " 'calculate',\n",
       " 'your',\n",
       " 'AC',\n",
       " 'If',\n",
       " 'you',\n",
       " 'have',\n",
       " 'multiple',\n",
       " 'features',\n",
       " 'that',\n",
       " 'give',\n",
       " 'you',\n",
       " 'different',\n",
       " 'ways',\n",
       " 'to',\n",
       " 'calculate']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phbtext[8000:8020]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20618be2",
   "metadata": {},
   "source": [
    "## Flesch–Kincaid readability test\n",
    "<img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/bd4916e193d2f96fa3b74ee258aaa6fe242e110e>\n",
    "\n",
    "This readability test was created to measure how easy a text is to read, it was formulated for use on technical manuals for the military and has been adopted into the educational field as well. The formula above results in a score, the higher the score, the easier the text is to read. There is a scale from 0-100 raning from 5th grade to Professional.\n",
    "\n",
    "[source](https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests)\n",
    "\n",
    "This comes with a translation of the score: The Grade Level Score\n",
    "<img src=https://readable.com/wp-content/uploads/2017/01/fleschkincaidchart.png>\n",
    "\n",
    "[source](https://readable.com/readability/flesch-reading-ease-flesch-kincaid-grade-level/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5901f93a",
   "metadata": {},
   "source": [
    "#### Syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05b0f364",
   "metadata": {},
   "outputs": [],
   "source": [
    "phbtext = [w.lower() for w in phbtext]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b0694d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = EspeakBackend('en-us')\n",
    "phbtextphon = backend.phonemize(phbtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f74d5740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kɑːntɛnts ',\n",
       " 'pɹɛfəs ',\n",
       " 'fɔːɹ ',\n",
       " 'ɪntɹədʌkʃən ',\n",
       " 'faɪv ',\n",
       " 'wɜːldz ',\n",
       " 'ʌv ',\n",
       " 'ɐdvɛntʃɚ ',\n",
       " 'faɪv ',\n",
       " 'juːzɪŋ ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phbtextphon[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b302243",
   "metadata": {},
   "source": [
    "Cool! This thing phonemizes numerals too! \n",
    "\n",
    "I was having a minor issue with cutting a phonemized word down to only its vowels to equate to number of syllables in the cases of dipthongs. It was splitting the diphthongs into two and adding to the syllable count. \n",
    "\n",
    "Because of that, what I decided to do was to abbreviate any dipthongs into just the first vowel of the two. It won't be the exact accurate representation of the vowels, but we don't need the exact representation of the vowels, we need to see the count of syllables, and that should work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86fa5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "phbtextphon = [(re.sub(r'(.*)eɪ(.*)', r'\\1e\\2', w)) for w in phbtextphon]\n",
    "phbtextphon = [(re.sub(r'(.*)oʊ(.*)', r'\\1o\\2', w)) for w in phbtextphon]\n",
    "phbtextphon = [(re.sub(r'(.*)aɪ(.*)', r'\\1a\\2', w)) for w in phbtextphon]\n",
    "phbtextphon = [(re.sub(r'(.*)aʊ(.*)', r'\\1a\\2', w)) for w in phbtextphon]\n",
    "phbtextphon = [(re.sub(r'(.*)ɔɪ(.*)', r'\\1ɔ\\2', w)) for w in phbtextphon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c767b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = ['ᵻ', 'ɪ', 'e', 'ɛ', 'æ', 'ʌ', 'ə', 'u', 'ʊ', 'ɔ', 'ɑ', 'i', 'ɐ', 'ɚ', 'ɜ', 'a', 'o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2da6e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "phbvowels = [[c for c in w if c in vowels] for w in phbtextphon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c519a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ɑ', 'ɛ'],\n",
       " ['ɛ', 'ə'],\n",
       " ['ɔ'],\n",
       " ['ɪ', 'ə', 'ʌ', 'ə'],\n",
       " ['a'],\n",
       " ['ɜ'],\n",
       " ['ʌ'],\n",
       " ['ɐ', 'ɛ', 'ɚ'],\n",
       " ['a'],\n",
       " ['u', 'ɪ']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phbvowels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd2afbf",
   "metadata": {},
   "source": [
    "Since this phonemizer captures numbers too and they won't be affecting our totals, I'm not going to be using the \"no numbers\" version of the text like I did in my first test. This captures things like page numbers in the table of contents which is maybe not perfect, but there are a lot of numbers throughout the text that are important parts of the text: calculating armor class, ability scores, rolling dice with different numbers of sides, so I want to keep them in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8197830",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = [len(w) for w in phbvowels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd62fbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 1, 4, 1, 1, 1, 3, 1, 2]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cffcf742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332504"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(count)  #sum of all values = count of all syllables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584322aa",
   "metadata": {},
   "source": [
    "Now this is interesting! 332,504. \n",
    "\n",
    "In the previous attempt for the full text including numbers there were 350,211 syllables counted, and without numbers there were 341,505. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f132a2f",
   "metadata": {},
   "source": [
    "#### Sentences\n",
    "\n",
    "NLTK is still the best bet for sentence tokenizing. And, again, we can't be 100% positive that this is entirely accurate. Some of these things are table of contents, some may be sentence fragments, etc. I feel confident this output is more accurate than the syllable tokenizer.\n",
    "\n",
    "Remember, tokenizing sentences on the \"text\" before we removed the punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c86bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5348868a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Not all characters wear armor or carry shields, however.',\n",
       " 'Without armor or a shield, your character’s AC equals 10 + his or her Dexterity modifier.',\n",
       " 'If your character wears armor, carries a shield, or both, calculate your AC using the rules in chapter 5.',\n",
       " 'Record your AC on your character sheet.',\n",
       " 'Your character needs to be proficient with armor and shields to wear and use them effectively, and your armor and shield proficiencies are determined by your class.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[400:405]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f8a75e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11046"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c419134",
   "metadata": {},
   "source": [
    "## Running the Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69bbdc2",
   "metadata": {},
   "source": [
    "### First: PHB text including numbers\n",
    "\n",
    "1. Reading Ease\n",
    "2. Grade Level Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e20a61bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.29047841319809"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "206.853-(1.015*(215058/11046))-(84.6*(332504/215058))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed8a3daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.247166031973116"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.39*(215058/11046))+(11.8*(332504/215058))-15.59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa50182",
   "metadata": {},
   "source": [
    "## Results (Part 2)\n",
    "\n",
    "Now this is really really interesting! \n",
    "\n",
    "As a reminder of what the first score looked like, with numbers (as numerals) included there was a rating of 49 and without numbers a more difficult score of 47. That was in the easier end of the \"difficult to read\" level/College reading level. \n",
    "\n",
    "With this method, a score of 56 puts it very slightly on the easier end of the \"fairly difficult to read\" scale (between 50-60) with a range of 10-12th grade. The grade score seems to reasonably match with a score of 10 = 1-th grade level.\n",
    "\n",
    "Again a reminder of other common texts scores:\n",
    "-Time Magazine : 52\n",
    "-Moby Dick : 57.9\n",
    "    - one particularly long sentence about sharks in chapter 64 has a readability score of −146.77\n",
    "-Highest (easiest) possible score is 121.22, every sentence must use only 1 syllable words (think Dr. Seuss!)\n",
    "\n",
    "### Thoughts\n",
    "\n",
    "While I still have my holdouts about the readability test in general, it's fascinating to see that the scored changed this much with a better syllable counting method alone! Everything else about the process is exactly the same. I think the easier score meshes better with my understanding and familiarity with the PHB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260a450",
   "metadata": {},
   "source": [
    "## SMOG Readability Test\n",
    "\n",
    "G. Harry McLaughlin created the SMOG (Simple Measure of Gobbledygook) in 1969 to measure text readability. There is a full breakdown of the formula [here](https://readabilityformulas.com/the-smog-readability-formula/), but it functions similarly to the Flesch–Kincaid test, and I'd like to compare.\n",
    "<img src=https://readabilityformulas.com/wp-content/uploads/01-SMOG-readability-formula.png>\n",
    "\n",
    "The SMOG test is made to be tested on 3 groups of ten sentences, from the beginning, middle, and end of a text, so I'll take some samples rather than the full text. Now, this is likely because the rest was being done by hand at the time of its creation, and this is easier to do than doing the whole book, but these are the instructions and so I will stick to them.\n",
    "\n",
    "So this formula basically can be simplified down to SQ RT of the total number of polysyllabic words plus 3. Since we're sampling only 30 sentences 30/30 is 1 anyway... There are simplified instructions linked below. \n",
    "\n",
    "Link to Ohio State instructions PDF [here](https://ogg.osu.edu/media/documents/health_lit/WRRSMOG_Example.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa670b",
   "metadata": {},
   "source": [
    "### Sampling from the text\n",
    "\n",
    "Knowing the beginning of the book is table of contents and the end is appendix, I want to select for a good option of 30 sentences. I'll do some searching and concatenating into a list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28380652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Because the DM can improvise to react to anything the players attempt, DND is infinitely flexible, and each adventure can be exciting and unexpected.',\n",
       " 'The game has no real end; when one story or quest wraps up, another one can begin, creating an ongoing story called a campaign.',\n",
       " 'Many people who play the game keep their campaigns going for months or years, meeting with their friends every week or so to pick up the story where they left off.',\n",
       " 'The adventurers grow in might as the campaign continues.',\n",
       " 'Each monster defeated, each adventure completed, and each treasure recovered not only adds to the continuing story, but also earns the adventurers new capabilities.',\n",
       " 'This increase in power is reflected by an adventurer’s level.',\n",
       " 'There’s no winning and losing in the Dungeons N Dragons game—at least, not the way those terms are usually understood.',\n",
       " 'Together, the DM and the players create an exciting story of bold adventurers who confront deadly perils.',\n",
       " 'sometimes an adventurer might come to a grisly end, torn apart by ferocious monsters or done in by a nefarious villain.',\n",
       " 'Even so, the other adventurers can search for powerful magic to revive their fallen comrade, or the player might choose to create a new character to carry on.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early = sents[84:94] #some introductory stuff about DND\n",
    "early "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06ac6ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Each target must make a Wisdom saving throw and falls unconscious for 10 minutes on a failed save.',\n",
       " 'A creature awakens if it takes damage or if someone uses an action to shake or slap it awake.',\n",
       " 'Stunning.',\n",
       " 'Each target must make a Wisdom saving throw and becomes stunned for 1 minute on a failed save.',\n",
       " 'Tasha ’s Hideous Laughter 1st-level enchantment Casting Time: 1 action Range: 30 feet Components: V, S, M (tiny tarts and a feather that is waved in the air) Duration: Concentration, up to 1 minute A creature of your choice that you can see within range perceives everything as hilariously funny and falls into fits of laughter if this spell affects it.',\n",
       " 'The target must succeed on a Wisdom saving throw or fall prone, becoming incapacitated and unable to stand up for the duration.',\n",
       " 'A creature with an Intelligence score of 4 or less isn’t affected.',\n",
       " 'At the end of each of its turns, and each time it takes damage, the target can make another Wisdom saving throw.',\n",
       " 'The target has advantage on the saving throw if it’s triggered by damage.',\n",
       " 'On a success, the spell ends.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "late = sents[9500:9510] #spells and spell descriptions\n",
    "late  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50726245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Only merchants, adventurers, and those offering professional services for hire commonly deal in coins.',\n",
       " 'Coinage Common coins come in several different denominations based on the relative worth of the metal from which they are made.',\n",
       " 'The three most common coins are the gold piece (gp), the silver piece (sp), and the copper piece (cp).',\n",
       " 'With one gold piece, a character can buy a belt pouch, 50 feet of good rope, or a goat.',\n",
       " 'A skilled (but not exceptional) artisan can earn one gold piece a day.',\n",
       " 'The gold piece is the standard unit of measure for wealth, even if the coin itself is not commonly used.',\n",
       " 'When merchants discuss deals that involve goods or services worth hundreds or thousands of gold pieces, the transactions don’t usually involve the exchange of individual coins.',\n",
       " 'Rather, the gold piece is a standard measure of value, and the actual exchange is in gold bars, letters of credit, or valuable goods.',\n",
       " 'One gold piece is worth ten silver pieces, the most prevalent coin among commoners.',\n",
       " 'A silver piece buys a laborer’s work for a day, a flask of lamp oil, or a night’s rest in a poor inn.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid = sents[4703:4713] #something around the middle point - looks like information about shopping/money\n",
    "mid  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24750ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testvals = early+mid+late\n",
    "len(testvals) #30 total sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac315968",
   "metadata": {},
   "source": [
    "### Polysyllabic Words\n",
    "\n",
    "For the SMOG test, these are defined as words 3 syllables or longer\n",
    "\n",
    "This is the test that I previously ran with the syllablizer and then secondarily by hand to compare and found a difference of 30 3+ syllable words. It counted 96 and when I counted by hand only found 66.\n",
    "\n",
    "I wanted to try it again this way to see if it's perfect, or if my method here still has room for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb035935",
   "metadata": {},
   "outputs": [],
   "source": [
    "wtoks = [tokenizer.tokenize(s) for s in testvals] #tokenized sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d31c531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "602"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = list(itertools.chain(*wtoks))\n",
    "len(merged) #merged into one long list, 602 words in 30 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4faaa11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "polysyl = backend.phonemize(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97b38038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bɪɡɪn ',\n",
       " 'kɹiːeɪɾɪŋ ',\n",
       " 'æn ',\n",
       " 'ɑːŋɡoʊɪŋ ',\n",
       " 'stɔːɹi ',\n",
       " 'kɔːld ',\n",
       " 'eɪ ',\n",
       " 'kæmpeɪn ',\n",
       " 'mɛni ',\n",
       " 'piːpəl ']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polysyl[40:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d05fe21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "polysyl = [(re.sub(r'(.*)eɪ(.*)', r'\\1e\\2', w)) for w in polysyl]\n",
    "polysyl = [(re.sub(r'(.*)oʊ(.*)', r'\\1o\\2', w)) for w in polysyl]\n",
    "polysyl = [(re.sub(r'(.*)aɪ(.*)', r'\\1a\\2', w)) for w in polysyl]\n",
    "polysyl = [(re.sub(r'(.*)aʊ(.*)', r'\\1a\\2', w)) for w in polysyl]\n",
    "polysyl = [(re.sub(r'(.*)ɔɪ(.*)', r'\\1ɔ\\2', w)) for w in polysyl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b926862",
   "metadata": {},
   "outputs": [],
   "source": [
    "polysylvow = [[c for c in w if c in vowels] for w in polysyl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2f3f7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 1, 3, 2, 1, 1, 2, 2, 2]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polycount = [len(w) for w in polysylvow]\n",
    "polycount[40:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee900fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 3, 4, 3, 3, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 4, 4, 5, 3, 4, 4, 3, 3]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multsyls = [w for w in polycount if w>=3]\n",
    "multsyls[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0b5dc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multsyls) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf9fa8",
   "metadata": {},
   "source": [
    "## SMOG Results\n",
    "\n",
    "Next step is to find the nearest perfect square to get the sqrt of that value: SQ RT of 64 is **8**\n",
    "\n",
    "Adding 3, this gives us grade levels of 11."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08a83ad",
   "metadata": {},
   "source": [
    "### The Hand Calculations\n",
    "\n",
    "When I counted by hand (as the test was designed to be done), I counted 66 3+ syllable words in our 30 sentences. \n",
    "\n",
    "It's still imperfect, but only by a difference of 4 and not an entire 30. In this instance, the nearest perfect square and, as a result, the grade level score is the same by both calculation methods. With a little finesse and investigtion into spots of inconsistency, this method could be really perfected! It's information I'm going to keep with my for future projects, for sure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7ed34b",
   "metadata": {},
   "source": [
    "## Renewed Thoughts about Readability Scores\n",
    "\n",
    "Really, my thoughts from my first [notebook](https://github.com/Data-Science-for-Linguists-2025/Critical-Role-Analysis/blob/39dc6f876da2527aa64be64ae34435e61daf5a31/notebooks/DND_Jargon.ipynb) are much the same. This methodology of calculating is a huge improvement, but my issues with the test in general are unchanged. The concept is great and I think it's a very cool idea. It's nice that it's fairly simple for application by non-linguists, but I believe there must be a better method for calculating readability than these tests offer. But overall, I'm glad I found these tests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96da590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSci",
   "language": "python",
   "name": "datasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
