{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5877ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  #just in case\n",
    "import nltk\n",
    "from nltk.tokenize import SyllableTokenizer  #for tokenizing syllables\n",
    "from nltk.tokenize import RegexpTokenizer   #for word tokenizing to ignore punctuation\n",
    "import itertools #used later to flatten/merge a list\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5239da",
   "metadata": {},
   "source": [
    "### How Jargon-y is DND?\n",
    "\n",
    "To take a look, I grabbed my copy of the Player's Handbook (PHB) and converted it to a text file. I won't be sharing since the copyright belongs to Wizards of the Coast, but I will be discussing my findings here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00196815",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/PHB.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7499b832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1220025"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f348dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "phbtext = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a358d4ff",
   "metadata": {},
   "source": [
    "Our total tokenized word count for the Player's Handbook is below. This excludes punctuation unlike in the usual nltk tokenizing, since the measurements I'm going to be using don't need that information. There's a short glance at a small section to get a feel for what we're looking at. The transformation into a .txt file was not perfect because of some text formatting in the original form, but I did the best I could without spending an excessive amount of time correcting every single issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "819b62c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215058"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phbtext) #total words (roughly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "774ac905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you',\n",
       " 'a',\n",
       " 'different',\n",
       " 'way',\n",
       " 'to',\n",
       " 'calculate',\n",
       " 'your',\n",
       " 'AC',\n",
       " 'If',\n",
       " 'you',\n",
       " 'have',\n",
       " 'multiple',\n",
       " 'features',\n",
       " 'that',\n",
       " 'give',\n",
       " 'you',\n",
       " 'different',\n",
       " 'ways',\n",
       " 'to',\n",
       " 'calculate']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phbtext[8000:8020]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f69aaa",
   "metadata": {},
   "source": [
    "#### On second thought...\n",
    "\n",
    "Some of the contents of this text is stuff like table of contents or an Appendix, which list page numbers. I don't think these would be considered part of the text... or would affect readability of the text. However, this is D&D... There is also a lot of talk about dice and numbers, ability scores, modifiers, rolling a D20, D10, D6 etc. I don't love ditching all instances of numbers, but I'm going to take a look at the difference in word count without the page numbers included to see the difference. At worst, I'll run the calculations twice and see how different the scores look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "308ad34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonums = re.sub(r\"\\d+\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81930d71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Contents',\n",
       " 'Preface',\n",
       " 'Introduction',\n",
       " 'Worlds',\n",
       " 'of',\n",
       " 'Adventure',\n",
       " 'Using',\n",
       " 'This',\n",
       " 'Book',\n",
       " 'How']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonumtxt = tokenizer.tokenize(nonums)\n",
    "nonumtxt[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18602f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206353"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nonumtxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e76b9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Contents',\n",
       " 'Preface',\n",
       " '4',\n",
       " 'Introduction',\n",
       " '5',\n",
       " 'Worlds',\n",
       " 'of',\n",
       " 'Adventure',\n",
       " '5',\n",
       " 'Using']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phbtext[:10] #for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20618be2",
   "metadata": {},
   "source": [
    "## Fleschâ€“Kincaid readability test\n",
    "<img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/bd4916e193d2f96fa3b74ee258aaa6fe242e110e>\n",
    "\n",
    "This readability test was created to measure how easy a text is to read, it was formulated for use on technical manuals for the military and has been adopted into the educational field as well. The formula above results in a score, the higher the score, the easier the text is to read. There is a scale from 0-100 raning from 5th grade to Professional.\n",
    "\n",
    "[source](https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests)\n",
    "\n",
    "This comes with a translation of the score: The Grade Level Score\n",
    "<img src=https://readable.com/wp-content/uploads/2017/01/fleschkincaidchart.png>\n",
    "\n",
    "[source](https://readable.com/readability/flesch-reading-ease-flesch-kincaid-grade-level/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bda5207",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSP = SyllableTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a55e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "syls = [SSP.tokenize(w) for w in phbtext]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25ff4f1",
   "metadata": {},
   "source": [
    "#### Syllables\n",
    "\n",
    "I tried multiple syllable splitters, and none were perfect, but NLTK's syllable tokenizer was easily the best among them. It's not perfect, and I give it some leeway because we are dealing here with a lot of invented fantasy words, but even regular words it struggles with. See \"ability\" and \"gnome\" below.\n",
    "\n",
    "It's doing its best, but there's room to grow. We'll take the score we get from our measurement very cautiously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2177c944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215058"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(syls) #same as tokens - each word is made into a sub-list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36b72937",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['gno', 'mes'],\n",
       " ['Most'],\n",
       " ['gno', 'mes'],\n",
       " ['in'],\n",
       " ['the'],\n",
       " ['worlds'],\n",
       " ['of'],\n",
       " ['DND'],\n",
       " ['a', 're'],\n",
       " ['rock'],\n",
       " ['gno', 'mes'],\n",
       " ['in', 'clu', 'ding'],\n",
       " ['the'],\n",
       " ['tin', 'ker'],\n",
       " ['gno', 'mes'],\n",
       " ['of'],\n",
       " ['the'],\n",
       " ['Dra', 'gon', 'lan', 'ce'],\n",
       " ['set', 'ting'],\n",
       " ['Abi', 'li', 'ty'],\n",
       " ['Sco', 're'],\n",
       " ['Increa', 'se'],\n",
       " ['Yo', 'ur'],\n",
       " ['Cons', 'ti', 'tu', 'tion'],\n",
       " ['sco', 're']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syls[20300:20325]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f14c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = [len(w) for w in syls] #len for each sublist in the larger list of syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62fea2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 3, 1, 2, 2, 1, 1, 4, 2, 3, 2, 2, 2, 4, 2]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count[20300:20325] #verification by looking at the same slice as above, looks accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cffcf742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350211"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(count)  #sum of all values = count of all syllables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab100ca7",
   "metadata": {},
   "source": [
    "#### Syllables p.2 (no numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd87ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonumsyls = [SSP.tokenize(w) for w in nonumtxt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2788ec88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206353"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nonumsyls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd1f9507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341505"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonumcount = [len(w) for w in nonumsyls]\n",
    "sum(nonumcount) #not a HUGE loss or change, but I'll keep this anyway just to see what changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f132a2f",
   "metadata": {},
   "source": [
    "#### Sentences\n",
    "\n",
    "Again, nltk is the best bet for sentence tokenizing. And, again, we can't be 100% positive that this is entirely accurate. Some of these things are table of contents, some may be sentence fragments, etc. I feel confident this output is more accurate than the syllable tokenizer.\n",
    "\n",
    "Remember, tokenizing sentences on the \"text\" before we removed the punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c86bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5348868a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Not all characters wear armor or carry shields, however.',\n",
       " 'Without armor or a shield, your characterâ€™s AC equals 10 + his or her Dexterity modifier.',\n",
       " 'If your character wears armor, carries a shield, or both, calculate your AC using the rules in chapter 5.',\n",
       " 'Record your AC on your character sheet.',\n",
       " 'Your character needs to be proficient with armor and shields to wear and use them effectively, and your armor and shield proficiencies are determined by your class.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[400:405]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f8a75e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11046"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107ef199",
   "metadata": {},
   "source": [
    "#### Sents p.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf2cfd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11027"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonumsents = nltk.sent_tokenize(nonums)\n",
    "len(nonumsents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c419134",
   "metadata": {},
   "source": [
    "## Running the Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69bbdc2",
   "metadata": {},
   "source": [
    "### First: PHB text including numbers\n",
    "\n",
    "1. Reading Ease\n",
    "2. Grade Level Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e20a61bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.3248589059024"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "206.853-(1.015*(215058/11046))-(84.6*(350211/215058))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed8a3daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.218729982163296"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.39*(215058/11046))+(11.8*(350211/215058))-15.59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc0a4b",
   "metadata": {},
   "source": [
    "### Second: PHB with numbers removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "509a7f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.882317229015655"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "206.853-(1.015*(206353/11046))-(84.6*(341505/206353))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1dd91c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.224157464103332"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.39*(206353/11046))+(11.8*(341505/206353))-15.59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa50182",
   "metadata": {},
   "source": [
    "Not all that different! That's interesting, that's cool to see. \n",
    "\n",
    "## Results\n",
    "\n",
    "According to the scores listed, a score of 47-49 lands the PHB at the easier end of \"difficult to read\" stating a College level. Since the removal of numbers (page numbers but also dice denominations and tutorial text about rolling dice and so on) Interesting that the removal of numbers increased the difficulty as much as it did. I suspect they were quite often tokenized as single-syllable words even though the majority of numbers are not single-syllable.\n",
    "\n",
    "I don't think it's an unreasonable score, but I take it cautiously.\n",
    "\n",
    "The score information at the wiki source for this readability test shares some other scores for popular texts to put this into some perspective:\n",
    "-Time Magazine : 52\n",
    "-Moby Dick : 57.9\n",
    "    - one particularly long sentence about sharks in chapter 64 has a readability score of âˆ’146.77\n",
    "-Highest (easiest) possible score is 121.22, every sentence must use only 1 syllable words (think Dr. Seuss!)\n",
    "\n",
    "### Thoughts\n",
    "\n",
    "The Readability Score is interesting. The Player's Handbook is no child's book, necessarily, but is it more difficult than Moby Dick? That gives me pause. It's ultimately a game instruction book and playable for children, is it just down to the fantasy words being used? Prestidigitation, Thaumaturgy, Polymorph... They're tricky words, but once you know the meaning, it's not that crazy. (It's probably down more to the syllable tokenizer).\n",
    "\n",
    "The Grade Score, which is very very similar both for the PHB with and without numbers included, makes sense as a good translation! A score of around 11 putting it on par with Jurassic Park. As someone who has read and owns the PHB, I can agree that feels about right.\n",
    "\n",
    "**However** I still take this score very cautiously. The syllable tokenizer is unreliable and both under and over tokenizes across the board. Not to mention that the text file itself was scraped from a PDF and is imperfect. Words are at times split apart because of original format text and caption information as well as the original format being two narrow columns of text per page. I did my best to correct as much of it as possible, but I'm sure there are parts I missed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260a450",
   "metadata": {},
   "source": [
    "## SMOG Readability Test\n",
    "\n",
    "G. Harry McLaughlin created the SMOG (Simple Measure of Gobbledygook) in 1969 to measure text readability. There is a full breakdown of the formula [here](https://readabilityformulas.com/the-smog-readability-formula/), but it functions similarly to the Fleschâ€“Kincaid test, and I'd like to compare.\n",
    "<img src=https://readabilityformulas.com/wp-content/uploads/01-SMOG-readability-formula.png>\n",
    "\n",
    "The SMOG test is made to be tested on 3 groups of ten sentences, from the beginning, middle, and end of a text, so I'll take some samples rather than the full text. Now, this is likely because the rest was being done by hand at the time of its creation, and this is easier to do than doing the whole book, but these are the instructions and so I will stick to them.\n",
    "\n",
    "So this formula basically can be simplified down to SQ RT of the total number of polysyllabic words plus 3. Since we're sampling only 30 sentences 30/30 is 1 anyway... There are simplified instructions linked below. \n",
    "\n",
    "Link to Ohio State instructions PDF [here](https://ogg.osu.edu/media/documents/health_lit/WRRSMOG_Example.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa670b",
   "metadata": {},
   "source": [
    "### Sampling from the text\n",
    "\n",
    "Knowing the beginning of the book is table of contents and the end is appendix, I want to select for a good option of 30 sentences. I'll do some searching and concatenating into a list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28380652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Because the DM can improvise to react to anything the players attempt, DND is infinitely flexible, and each adventure can be exciting and unexpected.',\n",
       " 'The game has no real end; when one story or quest wraps up, another one can begin, creating an ongoing story called a campaign.',\n",
       " 'Many people who play the game keep their campaigns going for months or years, meeting with their friends every week or so to pick up the story where they left off.',\n",
       " 'The adventurers grow in might as the campaign continues.',\n",
       " 'Each monster defeated, each adventure completed, and each treasure recovered not only adds to the continuing story, but also earns the adventurers new capabilities.',\n",
       " 'This increase in power is reflected by an adventurerâ€™s level.',\n",
       " 'Thereâ€™s no winning and losing in the Dungeons N Dragons gameâ€”at least, not the way those terms are usually understood.',\n",
       " 'Together, the DM and the players create an exciting story of bold adventurers who confront deadly perils.',\n",
       " 'sometimes an adventurer might come to a grisly end, torn apart by ferocious monsters or done in by a nefarious villain.',\n",
       " 'Even so, the other adventurers can search for powerful magic to revive their fallen comrade, or the player might choose to create a new character to carry on.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early = sents[84:94] #some introductory stuff about DND\n",
    "early "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06ac6ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Each target must make a Wisdom saving throw and falls unconscious for 10 minutes on a failed save.',\n",
       " 'A creature awakens if it takes damage or if someone uses an action to shake or slap it awake.',\n",
       " 'Stunning.',\n",
       " 'Each target must make a Wisdom saving throw and becomes stunned for 1 minute on a failed save.',\n",
       " 'Tasha â€™s Hideous Laughter 1st-level enchantment Casting Time: 1 action Range: 30 feet Components: V, S, M (tiny tarts and a feather that is waved in the air) Duration: Concentration, up to 1 minute A creature of your choice that you can see within range perceives everything as hilariously funny and falls into fits of laughter if this spell affects it.',\n",
       " 'The target must succeed on a Wisdom saving throw or fall prone, becoming incapacitated and unable to stand up for the duration.',\n",
       " 'A creature with an Intelligence score of 4 or less isnâ€™t affected.',\n",
       " 'At the end of each of its turns, and each time it takes damage, the target can make another Wisdom saving throw.',\n",
       " 'The target has advantage on the saving throw if itâ€™s triggered by damage.',\n",
       " 'On a success, the spell ends.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "late = sents[9500:9510] #spells and spell descriptions\n",
    "late  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50726245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Only merchants, adventurers, and those offering professional services for hire commonly deal in coins.',\n",
       " 'Coinage Common coins come in several different denominations based on the relative worth of the metal from which they are made.',\n",
       " 'The three most common coins are the gold piece (gp), the silver piece (sp), and the copper piece (cp).',\n",
       " 'With one gold piece, a character can buy a belt pouch, 50 feet of good rope, or a goat.',\n",
       " 'A skilled (but not exceptional) artisan can earn one gold piece a day.',\n",
       " 'The gold piece is the standard unit of measure for wealth, even if the coin itself is not commonly used.',\n",
       " 'When merchants discuss deals that involve goods or services worth hundreds or thousands of gold pieces, the transactions donâ€™t usually involve the exchange of individual coins.',\n",
       " 'Rather, the gold piece is a standard measure of value, and the actual exchange is in gold bars, letters of credit, or valuable goods.',\n",
       " 'One gold piece is worth ten silver pieces, the most prevalent coin among commoners.',\n",
       " 'A silver piece buys a laborerâ€™s work for a day, a flask of lamp oil, or a nightâ€™s rest in a poor inn.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid = sents[4703:4713] #something around the middle point - looks like information about shopping/money\n",
    "mid  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24750ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testvals = early+mid+late\n",
    "len(testvals) #30 total sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac315968",
   "metadata": {},
   "source": [
    "### Polysyllabic Words\n",
    "\n",
    "For the SMOG test, these are defined as words 3 syllables or longer\n",
    "\n",
    "wtoks creates a list of lists, which I merge into one long list and comprehend into a list of syllables and then syllable counts. Again, this is a little rough. The syllable counter is..... not the best. You can see in the preview below the mistakes it's making again. This module is good, but it needs a lot of work still. From there, select for only words 3 syllables or longer and get a count of how many appear (not a sum like before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb035935",
   "metadata": {},
   "outputs": [],
   "source": [
    "wtoks = [tokenizer.tokenize(s) for s in testvals] #tokenized sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d31c531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "602"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = list(itertools.chain(*wtoks))\n",
    "len(merged) #merged into one long list, 602 words in 30 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4faaa11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "polysyl = [SSP.tokenize(w) for w in merged]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97b38038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['be', 'gin'],\n",
       " ['crea', 'ting'],\n",
       " ['an'],\n",
       " ['on', 'going'],\n",
       " ['sto', 'ry'],\n",
       " ['cal', 'led'],\n",
       " ['a'],\n",
       " ['cam', 'paign'],\n",
       " ['Ma', 'ny'],\n",
       " ['peo', 'ple']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polysyl[40:50] #still..... imperfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffbefa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "polysylval = [len(w) for w in polysyl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6cd2ee8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 3, 5, 3, 4, 3, 4, 3, 3, 4, 3, 3, 4, 3, 3, 4, 3, 4, 5, 3, 3, 4, 3, 3]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multsyls = [w for w in polysylval if w>=3]\n",
    "multsyls[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36a46264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multsyls) #96 instances of multisyllabic words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf9fa8",
   "metadata": {},
   "source": [
    "Next step is to find the nearest perfect square to get the sqrt of that value: SQ RT of 100 is **10**\n",
    "\n",
    "Adding 3, this gives us grade levels of 13. (College?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08a83ad",
   "metadata": {},
   "source": [
    "### One More Thing...\n",
    "\n",
    "With our syllable tokens being a bit unsatisfying to me and with the idea in my mind that this test was designed to be done by hand..... I did it by hand. It's only 30 sentences I'm looking through. Let's see how far off the syllable tokenizer really is. After all, we see that it sometimes splits a 3 syllable word into 2 as well as ther reverse. Maybe it evens out...\n",
    "\n",
    "66 3+ syllable words in our 30 sentences when counted by hand. That's 30 entire instances where a token was incorrectly split into 3 syllables. Not ideal.\n",
    "\n",
    "This means our nearest perfect square is *actually* 64, which takes us to 8 for a grade level score of 11. This puts us quite in agreement with the results of the Fleschâ€“Kincaid test. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7ed34b",
   "metadata": {},
   "source": [
    "## Thoughts about Readability Scores\n",
    "\n",
    "While, overall, I'm okay with the grade level assessment of the readability of the Player's Handbook being around an 11th grade level, I have some reservations.\n",
    "\n",
    "1. What does that mean, exactly? \n",
    "    - A critique of these readability tests I've run into during my research is that they don't really take into account variation in readers. I assume it means \"what an average 11th grader is capable of reading\" and is based on statistics from schools and exams. \n",
    "    - It's imperfect but it's a reasonable label that can be understood by a typical person to indicate \"this is the developmental and educational point a person is at or near to understand this text\" and not strictly \"anyone younger than grade 11 students will struggle to understand this\"<br>\n",
    "<br>\n",
    "2. Readability doesn't necessarily correspond to comprehensibility. \n",
    "    - The IRS forms for filing individual taxes have a readability score of 8 (according to the PDF [here](https://www.irs.gov/pub/irs-soi/14rpreadabilityfederalincometaxsystem.pdf) on the IRS site of someone doing very similar assessment to this here). Maybe this is just me, but I've done my taxes the long way before and those are *not* an easy or pleasant read. \n",
    "    - So, great, you use shorter words on average and your syllable to word and sentence ratio indicates the reading level for 8th grade. How well written is the text? IRS forms are circuitous, confusing, and aggravating in a way that I feel complicates the readability very much!\n",
    "    - The PHB, in comparison, is written fairly colloquially in a modern, approachable tone. Sections are labeled and organized appropriately. It's been a while since I've been a new player, but I think that once the average person adapts to the specialty language, it is not very difficult to read. (definitely not more difficult than tax forms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d668244c",
   "metadata": {},
   "source": [
    "## The Question of Jargon\n",
    "\n",
    "I had the thought about specialized language in Dungeons & Dragons, and how to pinpoint exactly the most niche vocabulary. My method of narrowing down the vocabulary specific to DND is this:\n",
    "1. using Peter Norvig's [google](https://norvig.com/ngrams/) \"count_1w.txt\" corpus of 330,000(ish) of the most common English words (already made into tuples and pickled in Ling 1330). Isolate this list to create a list of just the words.\n",
    "2. using the tokenized list of words with numbers removed from the PHB, lowercase the full list and make a set to remove duplicates.\n",
    "3. cross check the two lists, return the words from the PHB not found in the Norvig data list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e73be1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../pickle_jar/goog1w_rank.pkl', 'rb')\n",
    "goog1w_rank = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b675724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'of', 'and', 'to', 'a']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#goog1w_rank is a list of tuples of words and their frequency counts. We just want the words for this.\n",
    "googwords = [w for (w,c) in goog1w_rank]\n",
    "googwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b277254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11269"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phbtoks = [w.lower() for w in nonumtxt]\n",
    "phbtypes = list(set(phbtoks))\n",
    "len(phbtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "146ee51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['portrait',\n",
       " 'discordant',\n",
       " 'companions',\n",
       " 'hits',\n",
       " 'clone',\n",
       " 'booms',\n",
       " 'beginning',\n",
       " 'function']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phbtypes[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1520bb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon = [w for w in phbtypes if w not in googwords]\n",
    "len(jargon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "136e67ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glimmerings',\n",
       " 'lunitari',\n",
       " 'loviatar',\n",
       " 'arrah',\n",
       " 'truesilver',\n",
       " 'habbakuk',\n",
       " 'volen',\n",
       " 'cutpurses',\n",
       " 'mindfire',\n",
       " 'seipora',\n",
       " 'flumphs',\n",
       " 'ensurate',\n",
       " 'damarans',\n",
       " 'seebo',\n",
       " 'carceri']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jargon[200:215]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fc2aa4",
   "metadata": {},
   "source": [
    "### About this Process\n",
    "\n",
    "I think it did really well! 836 specific tokens is not so bad, I think. It appears to me to be a non-comprehensive but quite informative list of words. It honestly was more effective than I expected it to be, and I feel pretty good about referencing this as a list of DND-specific words to check my speech data for references. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0166f4e",
   "metadata": {},
   "source": [
    "## The Jargon List\n",
    "\n",
    "So what kinds of words made it into the list?\n",
    "\n",
    "Looking through all the words we've isolated, I can sort them into 8 categories:\n",
    "1. **vocab**: subrace, clanless, cantrip, multiattack\n",
    "2. **names**: thamior, breena, stumbleduck, myrkul, agathys, keyleth, strahd\n",
    "3. **locations**: shadowfell, feywild, candlekeep\n",
    "4. **spells**: thaumaturgy, barkskin, truesight, enfeeblement, longstrider, cloudkill, revivify, countercharm, thunderwave\n",
    "5. **groups**: archfey, dragonborn, tiefling(s), lightfoots, merfolk, lizardfolk\n",
    "6. **creatures**: hippogriffs, wererats, tarrasque, owlbear\n",
    "7. **weapons**: greatclub, handaxes, scimitars, greataxe, longswords, shortbow, shortsword\n",
    "8. **languages**: dwarvish, undercommon, draconic\n",
    "\n",
    "The majority of these are names, by far.\n",
    "\n",
    "There are some words I'm surprised to have found in here, too! Words I think of as, sure, not exactly common, but still regular-ish English words: nonhostile, extradimensional, wineskin/waterskin, shapechanger, clumsier, crewmate, reckonings, longboats, nonplayer, semiconscious, feinting, falteringly, unadventurous, nonmagical, boastfulness, thunderously, glassblowers, gesticulation, otherwordly\n",
    "\n",
    "Some honorable mentions:<br>\n",
    "sibilants<br>\n",
    "blibdoolpoolp<br>\n",
    "mordenkainen<br>\n",
    "maglubiyet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8da1fe",
   "metadata": {},
   "source": [
    "### Is that everything...?\n",
    "\n",
    "No! Lillian actually in her recent response to my progress report asked, what about words that are pretty common in the English language but have a particular or unique meaning in DND? That certainly exists, and we'll take a little bit of a look. \n",
    "\n",
    "Some examples: perception, proficiency, halfling, beholder, polymorph, prestidigitation... to name a few\n",
    "\n",
    "I don't plan to go out of my way to add them into the Jargon list just yet though, since this endeavor is really secondary to the main goals of the project. It's still interesting!\n",
    "\n",
    "Finally, I noticed that a lot of the words I was surprised weren't in the Norvig list were expected words but with some kind of pre or suffix attached. Reckoning, longboat, sibilant, feint, boastful, thunderous, glassblower all apeared in the Norvig data. Gesticulate did not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9832689d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d63e6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to search for words in norvig \n",
    "rankdict = dict()\n",
    "for (index, (word, count)) in enumerate(goog1w_rank):\n",
    "    rankdict[word] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2b5753df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prestidigitation'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankdict['prestidigitation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6813f8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe90171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea1fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f5f442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSci",
   "language": "python",
   "name": "datasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
